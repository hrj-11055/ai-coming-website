#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Qwenæ¨¡å‹å¯¹æ¯”æµ‹è¯•å·¥å…·
ç”¨äºå¯¹æ¯”ä¸åŒQwenæ¨¡å‹åœ¨åŒä¸€æç¤ºè¯ä¸‹çš„æ•ˆæœ

æµ‹è¯•æ¨¡å‹ï¼š
- qwen-plus
- qwen-max-latest
- qwen3-max-preview

ä½¿ç”¨æ–¹æ³•ï¼š
python test_model_comparison.py
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import Dict, Any, List
import requests

# =====================================================
# é…ç½®åŒºåŸŸ
# =====================================================

class Config:
    """é…ç½®ç±»"""

    # é˜¿é‡Œäº‘ç™¾ç‚¼ API é…ç½®
    API_KEY = os.getenv('QWEN_API_KEY', 'sk-d110d2cda10d428a8e0b3551d7fc2105')
    API_URL = 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions'

    # Qwen æ¨¡å‹åˆ—è¡¨
    MODELS = [
        {
            'model_id': 'qwen-plus',
            'name': 'Qwen-Plus',
            'description': 'é€šç”¨å‹æ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½ä¸æˆæœ¬'
        },
        {
            'model_id': 'qwen-max-latest',
            'name': 'Qwen-Max-Latest',
            'description': 'æœ€å¼ºæ¨¡å‹ï¼Œè´¨é‡æœ€é«˜'
        },
        {
            'model_id': 'qwen3-max-preview',
            'name': 'Qwen3-Max-Preview',
            'description': 'Qwen3é¢„è§ˆç‰ˆï¼Œæœ€æ–°èƒ½åŠ›'
        }
    ]

    # æµ‹è¯•é—®é¢˜
    TEST_QUERIES = [
        "åšä¸€ä¸ªæ±½è½¦äº§ä¸šé“¾ç ”ç©¶",
        "åšä¸€ä¸ªæ±½è½¦ä¾›åº”é“¾ç ”ç©¶çš„æç¤ºè¯",
        "ç ”ç©¶æ™ºèƒ½åº§èˆ±çš„å‘å±•"
    ]


# =====================================================
# å·¥å…·å‡½æ•°
# =====================================================

def load_system_prompt() -> str:
    """åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
    try:
        prompt_file = Path(__file__).parent / 'config' / 'system-prompt.txt'
        if prompt_file.exists():
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt = f.read()
            print('âœ… ç³»ç»Ÿæç¤ºè¯å·²åŠ è½½\n')
            return prompt
    except Exception as e:
        print(f'âš ï¸  æ— æ³•åŠ è½½ç³»ç»Ÿæç¤ºè¯: {e}')
        print('å°†ä½¿ç”¨é»˜è®¤æç¤ºè¯\n')
    return 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚'


def print_separator(char='=', length=80):
    """æ‰“å°åˆ†éš”çº¿"""
    print(char * length)


def format_duration(ms: int) -> str:
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if ms >= 1000:
        return f'{ms/1000:.2f}ç§’'
    return f'{ms}æ¯«ç§’'


# =====================================================
# API è°ƒç”¨å‡½æ•°
# =====================================================

def call_qwen_model(model_config: Dict, query: str, system_prompt: str) -> Dict[str, Any]:
    """
    è°ƒç”¨æŒ‡å®šçš„ Qwen æ¨¡å‹

    Args:
        model_config: æ¨¡å‹é…ç½®å­—å…¸
        query: ç”¨æˆ·é—®é¢˜
        system_prompt: ç³»ç»Ÿæç¤ºè¯

    Returns:
        åŒ…å«å“åº”ç»“æœçš„å­—å…¸
    """
    model_id = model_config['model_id']
    model_name = model_config['name']

    start_time = time.time()

    try:
        response = requests.post(
            Config.API_URL,
            headers={
                'Content-Type': 'application/json',
                'Authorization': f"Bearer {Config.API_KEY}"
            },
            json={
                'model': model_id,
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': query}
                ],
                'temperature': 0.7,
                'max_tokens': 4000,
                'stream': False
            },
            timeout=120
        )

        end_time = time.time()
        duration = int((end_time - start_time) * 1000)

        response.raise_for_status()
        data = response.json()

        return {
            'model': model_name,
            'model_id': model_id,
            'query': query,
            'response': data['choices'][0]['message']['content'],
            'duration': duration,
            'duration_forma'
            'tted': format_duration(duration),
            'tokens': {
                'prompt': data.get('usage', {}).get('prompt_tokens', 0),
                'completion': data.get('usage', {}).get('completion_tokens', 0),
                'total': data.get('usage', {}).get('total_tokens', 0)
            },
            'raw': data
        }

    except requests.exceptions.RequestException as e:
        return {'error': str(e), 'model': model_name, 'model_id': model_id}
    except Exception as e:
        return {'error': f'æœªçŸ¥é”™è¯¯: {str(e)}', 'model': model_name, 'model_id': model_id}


# =====================================================
# å¯¹æ¯”æµ‹è¯•å‡½æ•°
# =====================================================

def run_comparison(query: str, system_prompt: str) -> List[Dict[str, Any]]:
    """
    è¿è¡Œå•ä¸ªæŸ¥è¯¢çš„å¯¹æ¯”æµ‹è¯•

    Args:
        query: æµ‹è¯•é—®é¢˜
        system_prompt: ç³»ç»Ÿæç¤ºè¯

    Returns:
        æ‰€æœ‰æ¨¡å‹çš„ç»“æœåˆ—è¡¨
    """
    print_separator()
    print(f'ğŸ“ æµ‹è¯•é—®é¢˜: {query}')
    print_separator()
    print()

    results = []

    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
    for i, model_config in enumerate(Config.MODELS, 1):
        model_name = model_config['name']
        print(f'[{i}/{len(Config.MODELS)}] ğŸ”„ æ­£åœ¨è°ƒç”¨ {model_name}...')

        result = call_qwen_model(model_config, query, system_prompt)
        results.append(result)

        if 'error' in result:
            print(f'  âŒ {model_name} è°ƒç”¨å¤±è´¥: {result["error"]}')
        else:
            print(f'  âœ… {model_name} å“åº”æˆåŠŸ')
            print(f'     ç”Ÿæˆæ—¶é—´: {result["duration_formatted"]}')
            print(f'     Tokens: {result["tokens"]["total"]} '
                  f'(è¾“å…¥: {result["tokens"]["prompt"]}, '
                  f'è¾“å‡º: {result["tokens"]["completion"]})')
        print()

    # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
    print_separator()
    print('ğŸ“Š å„æ¨¡å‹å›ç­”å¯¹æ¯”')
    print_separator()
    print()

    for result in results:
        if 'error' in result:
            continue

        print_separator('-')
        print(f'ğŸ”¹ {result["model"]} ({result["model_id"]})')
        print_separator('-')
        print(f'â±ï¸  ç”Ÿæˆæ—¶é—´: {result["duration_formatted"]}')
        print(f'ğŸ“ å›ç­”é•¿åº¦: {len(result["response"])} å­—ç¬¦')
        print(f'ğŸ“Š Tokenæ•°: {result["tokens"]["total"]}')
        print()
        print('å›ç­”å†…å®¹:')
        print('-' * 40)
        print(result['response'])
        print()
        print()

    return results


# =====================================================
# ä¸»å‡½æ•°
# =====================================================

def main():
    """ä¸»å‡½æ•°"""

    # æ‰“å°æ ‡é¢˜
    print()
    print('â–ˆ' * 80)
    print('â–ˆ' + ' ' * 78 + 'â–ˆ')
    print('â–ˆ' + '  Qwen æ¨¡å‹å¯¹æ¯”æµ‹è¯•å·¥å…·'.center(76) + '  â–ˆ')
    print('â–ˆ' + ' ' * 78 + 'â–ˆ')
    print('â–ˆ' * 80)
    print()

    # æ˜¾ç¤ºæµ‹è¯•æ¨¡å‹
    print('ğŸ¤– æµ‹è¯•æ¨¡å‹:')
    for i, model in enumerate(Config.MODELS, 1):
        print(f'  {i}. {model["name"]} ({model["model_id"]})')
        print(f'     {model["description"]}')
    print()

    # åŠ è½½ç³»ç»Ÿæç¤ºè¯
    system_prompt = load_system_prompt()

    # æ£€æŸ¥ API Key
    if not Config.API_KEY or 'your-qwen-api-key' in Config.API_KEY:
        print('âŒ è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® QWEN_API_KEY')
        print('   export QWEN_API_KEY=sk-your-actual-api-key')
        sys.exit(1)

    # æ˜¾ç¤ºæµ‹è¯•è®¡åˆ’
    print(f'ğŸ“‹ æµ‹è¯•è®¡åˆ’: å…± {len(Config.TEST_QUERIES)} ä¸ªé—®é¢˜\n')

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    all_results = []
    for i, query in enumerate(Config.TEST_QUERIES, 1):
        print(f'\n{"="*80}')
        print(f'æµ‹è¯•è¿›åº¦: {i}/{len(Config.TEST_QUERIES)}')
        print(f'{"="*80}\n')

        results = run_comparison(query, system_prompt)
        all_results.append({
            'query': query,
            'results': results
        })

        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªé—®é¢˜ï¼Œå»¶è¿Ÿä¸€ä¸‹é¿å…APIé™æµ
        if i < len(Config.TEST_QUERIES):
            print('â³ ç­‰å¾… 2 ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...\n')
            time.sleep(2)

    # æ±‡æ€»æŠ¥å‘Š
    print('\n' + 'â–ˆ' * 80)
    print('â–ˆ' + ' ' * 78 + 'â–ˆ')
    print('â–ˆ' + '  æµ‹è¯•å®Œæˆ - æ±‡æ€»æŠ¥å‘Š'.center(76) + '  â–ˆ')
    print('â–ˆ' + ' ' * 78 + 'â–ˆ')
    print('â–ˆ' * 80)
    print()

    # æ€§èƒ½å¯¹æ¯”è¡¨
    print('âš¡ æ€§èƒ½å¯¹æ¯”æ±‡æ€»')
    print_separator('-')
    print()

    # è¡¨å¤´
    print(f'{"é—®é¢˜":<30} | {"æ¨¡å‹":<20} | {"ç”Ÿæˆæ—¶é—´":<12} | {"Tokenæ•°":<10}')
    print('-' * 80)

    # æ•°æ®è¡Œ
    for test_idx, test_data in enumerate(all_results, 1):
        query_short = test_data['query'][:28] + '..' if len(test_data['query']) > 30 else test_data['query']

        for result in test_data['results']:
            if 'error' in result:
                status = 'âŒ å¤±è´¥'
                print(f'{query_short:<30} | {result["model"]:<20} | {status:<12} | {"N/A":<10}')
            else:
                print(f'{query_short:<30} | {result["model"]:<20} | {result["duration_formatted"]:<12} | {result["tokens"]["total"]:<10}')

    print()

    # ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹çš„å¹³å‡æ—¶é—´
    print('ğŸ“ˆ å„æ¨¡å‹å¹³å‡ç”Ÿæˆæ—¶é—´')
    print_separator('-')
    print()

    model_stats = {}
    for model in Config.MODELS:
        model_name = model['name']
        total_time = 0
        count = 0

        for test_data in all_results:
            for result in test_data['results']:
                if result.get('model') == model_name and 'error' not in result:
                    total_time += result['duration']
                    count += 1

        if count > 0:
            avg_time = total_time / count
            model_stats[model_name] = {
                'avg_time': avg_time,
                'count': count
            }

    # æ’åºå¹¶æ˜¾ç¤º
    sorted_models = sorted(model_stats.items(), key=lambda x: x[1]['avg_time'])

    for model_name, stats in sorted_models:
        print(f'  {model_name:<25} {format_duration(int(stats["avg_time"])):<15} '
              f'(åŸºäº{stats["count"]}ä¸ªæµ‹è¯•)')

    print()

    # Tokenä½¿ç”¨ç»Ÿè®¡
    print('ğŸ“Š å„æ¨¡å‹å¹³å‡Tokenä½¿ç”¨')
    print_separator('-')
    print()
    

    model_token_stats = {}
    for model in Config.MODELS:
        model_name = model['name']
        total_tokens = 0
        count = 0

        for test_data in all_results:
            for result in test_data['results']:
                if result.get('model') == model_name and 'error' not in result:
                    total_tokens += result['tokens']['total']
                    count += 1

        if count > 0:
            avg_tokens = total_tokens / count
            model_token_stats[model_name] = {
                'avg_tokens': avg_tokens,
                'count': count
            }

    # æ’åºå¹¶æ˜¾ç¤º
    sorted_tokens = sorted(model_token_stats.items(), key=lambda x: x[1]['avg_tokens'])

    for model_name, stats in sorted_tokens:
        print(f'  {model_name:<25} {int(stats["avg_tokens"]):>8} tokens  '
              f'(åŸºäº{stats["count"]}ä¸ªæµ‹è¯•)')

    print()

    print_separator()
    print('âœ… æµ‹è¯•å®Œæˆï¼')
    print_separator()
    print()

    # ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
    timestamp = int(time.time() * 1000)
    output_file = f'qwen-comparison-{timestamp}.json'

    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f'ğŸ“„ è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}')
        print()
    except Exception as e:
        print(f'âš ï¸  ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}')
        print()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­')
        sys.exit(0)
    except Exception as e:
        print(f'\n\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}')
        import traceback
        traceback.print_exc()
        sys.exit(1)
